gcloud dataproc clusters create bigdataproject-arjun \
  --region=us-central1 \
  --zone=us-central1-b \
  --image-version=2.0 \
  --master-machine-type=n1-standard-4 \
  --worker-machine-type=n1-standard-4 \
  --master-boot-disk-size=500GB \
  --worker-boot-disk-size=500GB \
  --num-workers=5 \
  --bucket=arjun-big-data-bucket \
  --optional-components=HIVE_WEBHCAT,JUPYTER,ZOOKEEPER \
  --enable-component-gateway \
  --metadata 'PIP_PACKAGES=spark-nlp spark-nlp-display google-cloud-bigquery google-cloud-storage' \
--initialization-actions gs://goog-dataproc-initialization-actions-us-central1/python/pip-install.sh \
--properties spark:spark.serializer=org.apache.spark.serializer.KryoSerializer,spark:spark.driver.maxResultSize=0,spark:spark.kryoserializer.buffer.max=2000M,spark:spark.jars.packages=com.johnsnowlabs.nlp:spark-nlp_2.12:3.3.4
